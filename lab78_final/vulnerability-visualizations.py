#!/usr/bin/env python3
import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from collections import Counter
from datetime import datetime

plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 12
plt.rcParams['figure.titlesize'] = 20

COLORS = {
    'high': '#e53e3e',      # Red for high severity/confidence
    'medium': '#ed8936',    # Orange for medium severity/confidence
    'low': '#38a169',       # Green for low severity/confidence
    'primary': '#4299e1',   # Blue for primary data
    'secondary': '#805ad5', # Purple for secondary data
    'neutral': '#718096',   # Gray for neutral data
}

def load_repository_results(repo_name, results_dir):
    csv_file = os.path.join(results_dir, repo_name, "results.csv")
    if not os.path.exists(csv_file):
        print(f"Results file not found for {repo_name}: {csv_file}")
        return None

    df = pd.read_csv(csv_file)
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date")
    df["unique_cwes"] = df["unique_cwes"].apply(
        lambda x: [] if pd.isna(x) else x.split(",") if x else []
    )
    
    return df

def create_summary_dashboard(repositories_data, output_dir):
    fig = plt.figure(figsize=(15, 12))
    fig.suptitle('Vulnerability Analysis Overview', fontsize=22, fontweight='bold')
    plt.subplots_adjust(hspace=0.4, wspace=0.3)
    gs = fig.add_gridspec(2, 2)
    
    # 1. Confidence Levels Plot
    ax1 = fig.add_subplot(gs[0, 0])
    repo_names = list(repositories_data.keys())
    
    high_conf = [df["high_confidence"].mean() for df in repositories_data.values()]
    medium_conf = [df["medium_confidence"].mean() for df in repositories_data.values()]
    low_conf = [df["low_confidence"].mean() for df in repositories_data.values()]
    
    x = np.arange(len(repo_names))
    width = 0.25
    
    ax1.bar(x - width, high_conf, width, label='High Confidence', color=COLORS['high'], alpha=0.8)
    ax1.bar(x, medium_conf, width, label='Medium Confidence', color=COLORS['medium'], alpha=0.8)
    ax1.bar(x + width, low_conf, width, label='Low Confidence', color=COLORS['low'], alpha=0.8)
    
    ax1.set_title('Average Confidence Levels by Repository')
    ax1.set_xticks(x)
    ax1.set_xticklabels(repo_names)
    ax1.set_ylabel('Average Issues Count')
    ax1.legend()
    
    # Add value labels
    for i, v in enumerate(high_conf):
        ax1.text(i - width, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=10)
    for i, v in enumerate(medium_conf):
        ax1.text(i, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=10)
    for i, v in enumerate(low_conf):
        ax1.text(i + width, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=10)
    
    # 2. Severity Levels Plot
    ax2 = fig.add_subplot(gs[0, 1])
    
    high_sev = [df["high_severity"].mean() for df in repositories_data.values()]
    medium_sev = [df["medium_severity"].mean() for df in repositories_data.values()]
    low_sev = [df["low_severity"].mean() for df in repositories_data.values()]
    
    ax2.bar(x - width, high_sev, width, label='High Severity', color=COLORS['high'], alpha=0.8)
    ax2.bar(x, medium_sev, width, label='Medium Severity', color=COLORS['medium'], alpha=0.8)
    ax2.bar(x + width, low_sev, width, label='Low Severity', color=COLORS['low'], alpha=0.8)
    
    ax2.set_title('Average Severity Levels by Repository')
    ax2.set_xticks(x)
    ax2.set_xticklabels(repo_names)
    ax2.set_ylabel('Average Issues Count')
    ax2.legend()
    
    # Add value labels
    for i, v in enumerate(high_sev):
        ax2.text(i - width, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=10)
    for i, v in enumerate(medium_sev):
        ax2.text(i, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=10)
    for i, v in enumerate(low_sev):
        ax2.text(i + width, v + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=10)
    
    # 3. Time Series of Issues
    ax3 = fig.add_subplot(gs[1, 0])
    
    for repo_name, df in repositories_data.items():
        # Using a moving average to smooth the lines:
        window_size = min(5, len(df) // 10) if len(df) > 10 else 1
        ax3.plot(
            range(len(df)),
            df["high_severity"].rolling(window=window_size).mean(),
            label=f"{repo_name}",
            alpha=0.8,
            linewidth=2.5
        )
    
    ax3.set_title('High Severity Issues Over Time')
    ax3.set_xlabel('Commit Sequence')
    ax3.set_ylabel('Number of High Severity Issues')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. CWE Distribution
    ax4 = fig.add_subplot(gs[1, 1])
    
    # Collecting all CWEs from all repositories
    all_cwes = []
    for repo_name, df in repositories_data.items():
        for cwes in df["unique_cwes"]:
            all_cwes.extend(cwes)
    
    # Count CWEs and get top ones
    cwe_counts = Counter(all_cwes)
    top_cwes = cwe_counts.most_common(8)  # Top 8 CWEs
    
    if top_cwes:
        cwe_ids = [f"CWE-{cwe}" for cwe, _ in top_cwes]
        cwe_values = [count for _, count in top_cwes]
        
        # Create horizontal bar chart
        bars = ax4.barh(cwe_ids, cwe_values, color=COLORS['primary'], alpha=0.8)
        ax4.set_title('Most Common CWEs Across All Repositories')
        ax4.set_xlabel('Frequency')
        
        # Add value labels
        for bar in bars:
            width = bar.get_width()
            ax4.text(width + 0.5, bar.get_y() + bar.get_height()/2, 
                    f'{width:.0f}', ha='left', va='center', fontsize=10)
    else:
        ax4.text(0.5, 0.5, "No CWEs found", ha='center', va='center', fontsize=14)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for the main title
    plt.savefig(os.path.join(output_dir, "summary_dashboard.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    print(f"Created summary dashboard: {os.path.join(output_dir, 'summary_dashboard.png')}")

def visualize_rq1_high_severity(repositories_data, output_dir):
    """
    Visualize RQ1: When are vulnerabilities with high severity introduced and fixed 
    along the development timeline in OSS repositories?
    """
    # We consider a vulnerability fixed when the count decreases from one commit to the next
    for repo_name, df in repositories_data.items():
        # Calculating the changes in high severity issues between commits
        df["high_severity_change"] = df["high_severity"].diff()
        df["high_severity_introduced"] = df["high_severity_change"].apply(lambda x: max(0, x))
        df["high_severity_fixed"] = df["high_severity_change"].apply(lambda x: max(0, -x))
    
    # Figure for introduction and fix percentages
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 16))
    fig.suptitle('RQ1: High Severity Vulnerabilities Introduction and Fixing', fontsize=22, fontweight='bold')
    
    # Plot 1: Percentage of commits that introduce/fix vulnerabilities
    repo_names = []
    introduced_pct = []
    fixed_pct = []
    
    for repo_name, df in repositories_data.items():
        repo_names.append(repo_name)
        introduced_pct.append((df["high_severity_introduced"] > 0).mean() * 100)
        fixed_pct.append((df["high_severity_fixed"] > 0).mean() * 100)
    
    x = np.arange(len(repo_names))
    width = 0.35
    
    intro_bars = ax1.bar(x - width/2, introduced_pct, width, label='Introduced', color=COLORS['high'], alpha=0.8)
    fix_bars = ax1.bar(x + width/2, fixed_pct, width, label='Fixed', color=COLORS['low'], alpha=0.8)
    
    # Add value labels
    for bar in intro_bars:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                f'{height:.1f}%', ha='center', va='bottom', fontsize=12)
    
    for bar in fix_bars:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                f'{height:.1f}%', ha='center', va='bottom', fontsize=12)
    
    ax1.set_title('Percentage of Commits that Introduce or Fix High Severity Vulnerabilities')
    ax1.set_ylabel('Percentage of Commits')
    ax1.set_xticks(x)
    ax1.set_xticklabels(repo_names)
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)
    
    # Calculate overall averages for annotation
    avg_introduced = sum(introduced_pct) / len(introduced_pct) if introduced_pct else 0
    avg_fixed = sum(fixed_pct) / len(fixed_pct) if fixed_pct else 0
    ratio = avg_fixed / avg_introduced if avg_introduced > 0 else 0
    
    # Add annotation box with overall statistics
    text_str = (f"Overall Statistics:\n"
                f"• Avg. % of commits introducing vulnerabilities: {avg_introduced:.1f}%\n"
                f"• Avg. % of commits fixing vulnerabilities: {avg_fixed:.1f}%\n"
                f"• Fix-to-Introduce Ratio: {ratio:.2f}")
    
    props = dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.7)
    ax1.text(0.05, 0.95, text_str, transform=ax1.transAxes, fontsize=12,
             verticalalignment='top', bbox=props)
    
    # Plot 2: Timeline of high severity issues (stacked area chart)
    for repo_name, df in repositories_data.items():
        # Convert commit sequence to percentage for x-axis normalization
        x_vals = np.linspace(0, 100, len(df))
        # Use rolling average to smooth the curve
        window_size = min(5, len(df) // 10) if len(df) > 10 else 1
        y_vals = df["high_severity"].rolling(window=window_size).mean().fillna(method='bfill').fillna(method='ffill')
        
        ax2.plot(x_vals, y_vals, label=repo_name, linewidth=2.5, alpha=0.8)
    
    ax2.set_title('Timeline of High Severity Issues (Normalized)')
    ax2.set_xlabel('Development Timeline (% of Commits)')
    ax2.set_ylabel('Number of High Severity Issues')
    ax2.legend(loc='best')
    ax2.grid(True, alpha=0.3)
    
    # Add annotations for key observations
    max_vals = {}
    min_vals = {}
    for repo_name, df in repositories_data.items():
        # Skip repo if not enough data points
        if len(df) < 10:
            continue
        
        window_size = min(5, len(df) // 10)
        smoothed = df["high_severity"].rolling(window=window_size).mean().fillna(method='bfill').fillna(method='ffill')
        max_idx = smoothed.idxmax()
        min_idx = smoothed.idxmin()
        max_val = smoothed[max_idx]
        min_val = smoothed[min_idx]
        
        # Store for later annotation
        max_vals[repo_name] = (max_idx / len(df) * 100, max_val)
        min_vals[repo_name] = (min_idx / len(df) * 100, min_val)
    
    # Add peak annotations (selectively to avoid clutter)
    for repo_name, (x_pos, y_val) in list(max_vals.items())[:2]:  # Annotate only first 2 repos
        ax2.annotate(f"Peak: {y_val:.1f}",
                    xy=(x_pos, y_val), xycoords='data',
                    xytext=(10, 10), textcoords='offset points',
                    arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2"))
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for the main title
    plt.savefig(os.path.join(output_dir, "rq1_high_severity_analysis.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    # Additional visualization: Average vulnerabilities per commit
    fig, ax = plt.subplots(figsize=(12, 8))
    
    avg_introduced_per_commit = []
    avg_fixed_per_commit = []
    
    for repo_name, df in repositories_data.items():
        introduced_commits = df[df["high_severity_introduced"] > 0]
        fixed_commits = df[df["high_severity_fixed"] > 0]
        
        avg_introduced = introduced_commits["high_severity_introduced"].mean() if len(introduced_commits) > 0 else 0
        avg_fixed = fixed_commits["high_severity_fixed"].mean() if len(fixed_commits) > 0 else 0
        
        avg_introduced_per_commit.append(avg_introduced)
        avg_fixed_per_commit.append(avg_fixed)
    
    x = np.arange(len(repo_names))
    width = 0.35
    
    intro_bars = ax.bar(x - width/2, avg_introduced_per_commit, width, label='Introduced', color=COLORS['high'], alpha=0.8)
    fix_bars = ax.bar(x + width/2, avg_fixed_per_commit, width, label='Fixed', color=COLORS['low'], alpha=0.8)
    
    # Add value labels
    for bar in intro_bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, height + 0.05,
               f'{height:.1f}', ha='center', va='bottom', fontsize=10)
    
    for bar in fix_bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, height + 0.05,
               f'{height:.1f}', ha='center', va='bottom', fontsize=10)
    
    ax.set_title('Average High Severity Vulnerabilities per Commit')
    ax.set_ylabel('Average Number of Vulnerabilities')
    ax.set_xticks(x)
    ax.set_xticklabels(repo_names)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "rq1_avg_vulnerabilities_per_commit.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    print(f"Created RQ1 visualizations in {output_dir}")
    
    # Return summary statistics
    summary = {
        "overall": {
            "avg_percent_introducing": avg_introduced,
            "avg_percent_fixing": avg_fixed,
            "ratio_fix_to_introduce": ratio
        },
        "repo_stats": {}
    }
    
    for i, repo_name in enumerate(repo_names):
        summary["repo_stats"][repo_name] = {
            "percent_introducing": introduced_pct[i],
            "percent_fixing": fixed_pct[i],
            "avg_vulnerabilities_introduced_per_commit": avg_introduced_per_commit[i],
            "avg_vulnerabilities_fixed_per_commit": avg_fixed_per_commit[i]
        }
    
    return summary

def visualize_rq2_severity_patterns(repositories_data, output_dir):
    """
    Visualize RQ2: Do vulnerabilities of different severity have the same pattern
    of introduction and elimination?
    """
    # Calculate changes for each severity level across all repositories
    for repo_name, df in repositories_data.items():
        # High severity
        df["high_severity_change"] = df["high_severity"].diff()
        df["high_severity_introduced"] = df["high_severity_change"].apply(lambda x: max(0, x))
        df["high_severity_fixed"] = df["high_severity_change"].apply(lambda x: max(0, -x))
        
        # Medium severity
        df["medium_severity_change"] = df["medium_severity"].diff()
        df["medium_severity_introduced"] = df["medium_severity_change"].apply(lambda x: max(0, x))
        df["medium_severity_fixed"] = df["medium_severity_change"].apply(lambda x: max(0, -x))
        
        # Low severity
        df["low_severity_change"] = df["low_severity"].diff()
        df["low_severity_introduced"] = df["low_severity_change"].apply(lambda x: max(0, x))
        df["low_severity_fixed"] = df["low_severity_change"].apply(lambda x: max(0, -x))
    
    # Create a figure with 3 subplots
    fig = plt.figure(figsize=(15, 18))
    fig.suptitle('RQ2: Patterns of Introduction and Elimination Across Severity Levels', 
                fontsize=22, fontweight='bold')
    
    # Add a bit more space between subplots
    plt.subplots_adjust(hspace=0.3)
    
    # Get repo names for all plots
    repo_names = list(repositories_data.keys())
    x = np.arange(len(repo_names))
    width = 0.25
    
    # Subplot 1: Introduction rates by severity
    ax1 = fig.add_subplot(3, 1, 1)
    
    high_intro_rates = []
    medium_intro_rates = []
    low_intro_rates = []
    
    for repo_name, df in repositories_data.items():
        high_intro_rates.append((df["high_severity_introduced"] > 0).mean() * 100)
        medium_intro_rates.append((df["medium_severity_introduced"] > 0).mean() * 100)
        low_intro_rates.append((df["low_severity_introduced"] > 0).mean() * 100)
    
    ax1.bar(x - width, high_intro_rates, width, label='High Severity', color=COLORS['high'], alpha=0.8)
    ax1.bar(x, medium_intro_rates, width, label='Medium Severity', color=COLORS['medium'], alpha=0.8)
    ax1.bar(x + width, low_intro_rates, width, label='Low Severity', color=COLORS['low'], alpha=0.8)
    
    ax1.set_title('Introduction Rate by Severity Level')
    ax1.set_ylabel('Percentage of Commits Introducing Vulnerabilities')
    ax1.set_xticks(x)
    ax1.set_xticklabels(repo_names)
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)
    
    # Add annotations for key observations
    high_intro_avg = sum(high_intro_rates) / len(high_intro_rates) if high_intro_rates else 0
    medium_intro_avg = sum(medium_intro_rates) / len(medium_intro_rates) if medium_intro_rates else 0
    low_intro_avg = sum(low_intro_rates) / len(low_intro_rates) if low_intro_rates else 0
    
    text_str = (f"Overall Averages:\n"
                f"• High: {high_intro_avg:.1f}%\n"
                f"• Medium: {medium_intro_avg:.1f}%\n"
                f"• Low: {low_intro_avg:.1f}%")
    
    props = dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.7)
    ax1.text(0.05, 0.95, text_str, transform=ax1.transAxes, fontsize=12,
            verticalalignment='top', bbox=props)
    
    # Subplot 2: Fix rates by severity
    ax2 = fig.add_subplot(3, 1, 2)
    
    high_fix_rates = []
    medium_fix_rates = []
    low_fix_rates = []
    
    for repo_name, df in repositories_data.items():
        high_fix_rates.append((df["high_severity_fixed"] > 0).mean() * 100)
        medium_fix_rates.append((df["medium_severity_fixed"] > 0).mean() * 100)
        low_fix_rates.append((df["low_severity_fixed"] > 0).mean() * 100)
    
    ax2.bar(x - width, high_fix_rates, width, label='High Severity', color=COLORS['high'], alpha=0.8)
    ax2.bar(x, medium_fix_rates, width, label='Medium Severity', color=COLORS['medium'], alpha=0.8)
    ax2.bar(x + width, low_fix_rates, width, label='Low Severity', color=COLORS['low'], alpha=0.8)
    
    ax2.set_title('Fix Rate by Severity Level')
    ax2.set_ylabel('Percentage of Commits Fixing Vulnerabilities')
    ax2.set_xticks(x)
    ax2.set_xticklabels(repo_names)
    ax2.legend()
    ax2.grid(axis='y', alpha=0.3)
    
    # Add annotations for key observations
    high_fix_avg = sum(high_fix_rates) / len(high_fix_rates) if high_fix_rates else 0
    medium_fix_avg = sum(medium_fix_rates) / len(medium_fix_rates) if medium_fix_rates else 0
    low_fix_avg = sum(low_fix_rates) / len(low_fix_rates) if low_fix_rates else 0
    
    text_str = (f"Overall Averages:\n"
                f"• High: {high_fix_avg:.1f}%\n"
                f"• Medium: {medium_fix_avg:.1f}%\n"
                f"• Low: {low_fix_avg:.1f}%")
    
    ax2.text(0.05, 0.95, text_str, transform=ax2.transAxes, fontsize=12,
            verticalalignment='top', bbox=props)
    
    # Subplot 3: Fix/Introduction ratio
    ax3 = fig.add_subplot(3, 1, 3)
    
    high_ratios = []
    medium_ratios = []
    low_ratios = []
    
    for i in range(len(repo_names)):
        high_ratios.append(high_fix_rates[i] / high_intro_rates[i] if high_intro_rates[i] > 0 else 0)
        medium_ratios.append(medium_fix_rates[i] / medium_intro_rates[i] if medium_intro_rates[i] > 0 else 0)
        low_ratios.append(low_fix_rates[i] / low_intro_rates[i] if low_intro_rates[i] > 0 else 0)
    
    ax3.bar(x - width, high_ratios, width, label='High Severity', color=COLORS['high'], alpha=0.8)
    ax3.bar(x, medium_ratios, width, label='Medium Severity', color=COLORS['medium'], alpha=0.8)
    ax3.bar(x + width, low_ratios, width, label='Low Severity', color=COLORS['low'], alpha=0.8)
    
    # Add horizontal line at y=1.0 (balance point)
    ax3.axhline(y=1.0, color='black', linestyle='--', alpha=0.7)
    ax3.text(x[-1] + width + 0.2, 1.0, 'Balance point', verticalalignment='center')
    
    ax3.set_title('Fix-to-Introduction Ratio by Severity Level')
    ax3.set_ylabel('Ratio (Fix Rate / Introduction Rate)')
    ax3.set_xticks(x)
    ax3.set_xticklabels(repo_names)
    ax3.legend()
    ax3.grid(axis='y', alpha=0.3)
    
    # Add annotations for key observations
    high_ratio_avg = sum(high_ratios) / len(high_ratios) if high_ratios else 0
    medium_ratio_avg = sum(medium_ratios) / len(medium_ratios) if medium_ratios else 0
    low_ratio_avg = sum(low_ratios) / len(low_ratios) if low_ratios else 0
    
    text_str = (f"Overall Averages:\n"
                f"• High: {high_ratio_avg:.2f}\n"
                f"• Medium: {medium_ratio_avg:.2f}\n"
                f"• Low: {low_ratio_avg:.2f}\n\n"
                f"Ratios < 1: More vulnerabilities introduced than fixed\n"
                f"Ratios > 1: More vulnerabilities fixed than introduced")
    
    ax3.text(0.05, 0.95, text_str, transform=ax3.transAxes, fontsize=12,
            verticalalignment='top', bbox=props)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for the main title
    plt.savefig(os.path.join(output_dir, "rq2_severity_patterns.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    print(f"Created RQ2 visualizations in {output_dir}")
    
    # Create a second visualization: severity trends over time
    fig, axes = plt.subplots(len(repo_names), 1, figsize=(12, 5 * len(repo_names)))
    if len(repo_names) == 1:
        axes = [axes]  # Ensure axes is a list for single repository
    
    for i, repo_name in enumerate(repo_names):
        df = repositories_data[repo_name]
        
        # Normalize the x-axis to percentage of development timeline
        x_vals = np.linspace(0, 100, len(df))
        
        # Use a moving average to smooth the data
        window_size = min(5, len(df) // 10) if len(df) > 10 else 1
        
        # Plot the smoothed data
        axes[i].plot(x_vals, df["high_severity"].rolling(window=window_size).mean().fillna(method='bfill').fillna(method='ffill'), 
                    color=COLORS['high'], linewidth=2.5, label='High Severity')
        axes[i].plot(x_vals, df["medium_severity"].rolling(window=window_size).mean().fillna(method='bfill').fillna(method='ffill'), 
                    color=COLORS['medium'], linewidth=2.5, label='Medium Severity')
        axes[i].plot(x_vals, df["low_severity"].rolling(window=window_size).mean().fillna(method='bfill').fillna(method='ffill'), 
                    color=COLORS['low'], linewidth=2.5, label='Low Severity')
        
        axes[i].set_title(f'Severity Trends Over Time: {repo_name}')
        axes[i].set_xlabel('Development Timeline (%)')
        axes[i].set_ylabel('Number of Issues')
        axes[i].legend()
        axes[i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "rq2_severity_trends.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    # Return summary statistics
    summary = {
        "severity_comparisons": {
            "introduction_rates": {
                "high_severity_avg": high_intro_avg,
                "medium_severity_avg": medium_intro_avg,
                "low_severity_avg": low_intro_avg
            },
            "fix_rates": {
                "high_severity_avg": high_fix_avg,
                "medium_severity_avg": medium_fix_avg,
                "low_severity_avg": low_fix_avg
            },
            "fix_to_intro_ratios": {
                "high_severity_avg": high_ratio_avg,
                "medium_severity_avg": medium_ratio_avg,
                "low_severity_avg": low_ratio_avg
            }
        },
        "repo_stats": {}
    }
    
    for i, repo_name in enumerate(repo_names):
        summary["repo_stats"][repo_name] = {
            "high_severity": {
                "intro_rate": high_intro_rates[i],
                "fix_rate": high_fix_rates[i],
                "ratio": high_ratios[i]
            },
            "medium_severity": {
                "intro_rate": medium_intro_rates[i],
                "fix_rate": medium_fix_rates[i],
                "ratio": medium_ratios[i]
            },
            "low_severity": {
                "intro_rate": low_intro_rates[i],
                "fix_rate": low_fix_rates[i],
                "ratio": low_ratios[i]
            }
        }
    
    return summary

def visualize_rq3_cwe_analysis(repositories_data, output_dir):
    """
    Visualize RQ3: Which CWEs are the most frequent across different OSS repositories?
    """
    # Collect all CWEs from all repositories
    all_cwes = []
    repo_cwes = {}
    
    for repo_name, df in repositories_data.items():
        repo_cwes[repo_name] = []
        for cwes in df["unique_cwes"]:
            repo_cwes[repo_name].extend(cwes)
            all_cwes.extend(cwes)
    
    # Count the overall CWE frequencies
    cwe_counts = Counter(all_cwes)
    
    if not all_cwes:
        print("WARNING: No CWEs found in any repository. Cannot answer RQ3.")
        
        plt.figure(figsize=(10, 6))
        plt.text(
            0.5, 0.5, "No CWEs found in any repository",
            horizontalalignment="center", verticalalignment="center", fontsize=16
        )
        plt.axis("off")
        plt.savefig(os.path.join(output_dir, "rq3_no_cwes.png"))
        plt.close()
        
        return {
            "overall_top_cwes": {},
            "repository_top_cwes": {repo_name: {} for repo_name in repositories_data.keys()}
        }
    
    # Get top CWEs
    top_cwes = cwe_counts.most_common(min(10, len(cwe_counts)))
    
    # Create bar chart of top CWEs
    fig, ax = plt.subplots(figsize=(12, 8))
    
    labels = [f"CWE-{cwe}" for cwe, _ in top_cwes]
    values = [count for _, count in top_cwes]
    
    bars = ax.bar(labels, values, color=COLORS['primary'], alpha=0.8)
    
    # Add value labels
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
               f'{height:.0f}', ha='center', va='bottom', fontsize=12)
    
    ax.set_title('Most Frequent CWEs Across All Repositories', fontsize=16)
    ax.set_xlabel('CWE ID', fontsize=14)
    ax.set_ylabel('Frequency', fontsize=14)
    ax.set_xticklabels(labels, rotation=45, ha='right')
    ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "rq3_top_cwes.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    # Create heatmap showing CWE distribution across repositories
    if top_cwes and len(repo_cwes) > 1:  # Only create heatmap if we have multiple repos and CWEs
        top_cwe_ids = [cwe for cwe, _ in top_cwes]
        repo_cwe_matrix = []
        repo_names = []
        
        for repo_name, cwes in repo_cwes.items():
            # Skip repos with no CWEs
            if not cwes:
                continue
                
            repo_names.append(repo_name)
            
            # Count CWEs for this repository
            repo_counter = Counter(cwes)
            
            # Create a row for the matrix
            row = [repo_counter.get(cwe, 0) for cwe in top_cwe_ids]
            repo_cwe_matrix.append(row)
        
        # Only create heatmap if we have data
        if repo_names and repo_cwe_matrix and len(repo_cwe_matrix[0]) > 0:
            fig, ax = plt.subplots(figsize=(14, 8))
            im = ax.imshow(repo_cwe_matrix, cmap='YlOrRd')
            cbar = ax.figure.colorbar(im, ax=ax)
            cbar.ax.set_ylabel('Frequency', rotation=-90, va="bottom")
            ax.set_xticks(np.arange(len(top_cwe_ids)))
            ax.set_yticks(np.arange(len(repo_names)))
            ax.set_xticklabels([f"CWE-{cwe}" for cwe in top_cwe_ids])
            ax.set_yticklabels(repo_names)
            plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")
            
            # Loop over data dimensions and create text annotations
            for i in range(len(repo_names)):
                for j in range(len(top_cwe_ids)):
                    text = ax.text(j, i, repo_cwe_matrix[i][j],
                                ha="center", va="center", color="black" if repo_cwe_matrix[i][j] < im.norm(im.cmap.N//2) else "white")
            
            ax.set_title("Distribution of Top CWEs Across Repositories", fontsize=16)
            fig.tight_layout()
            plt.savefig(os.path.join(output_dir, "rq3_cwe_heatmap.png"), dpi=300, bbox_inches='tight')
            plt.close(fig)
    
    # Create a pie chart of top 5 CWEs
    top5_cwes = cwe_counts.most_common(min(5, len(cwe_counts)))
    
    fig, ax = plt.subplots(figsize=(10, 10))
    
    labels = [f"CWE-{cwe}" for cwe, _ in top5_cwes]
    values = [count for _, count in top5_cwes]
    colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99','#c2c2f0']
    
    wedges, texts, autotexts = ax.pie(values, autopct='%1.1f%%', labels=labels, colors=colors,
                                      textprops={'fontsize': 12}, startangle=90)
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontsize(12)
        autotext.set_fontweight('bold')
    
    ax.set_title('Top 5 Most Common CWEs', fontsize=16)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "rq3_top_cwes_pie.png"), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    print(f"Created RQ3 visualizations in {output_dir}")
    
    # Return summary data
    summary = {
        "overall_top_cwes": {f"CWE-{cwe}": count for cwe, count in top_cwes},
        "repository_top_cwes": {}
    }
    
    for repo_name, cwes in repo_cwes.items():
        if cwes:
            repo_counter = Counter(cwes)
            summary["repository_top_cwes"][repo_name] = {
                f"CWE-{cwe}": count for cwe, count in repo_counter.most_common(5)
            }
        else:
            summary["repository_top_cwes"][repo_name] = {}
    
    return summary

def main():
    base_dir = "bandit_analysis_results"
    output_dir = os.path.join(base_dir, "analysis_outputs")
    os.makedirs(output_dir, exist_ok=True)
    repositories = ["bandit", "manim", "flask"]
    repositories_data = {}
    
    # Load repository data
    for repo_name in repositories:
        print(f"Loading data for {repo_name}...")
        df = load_repository_results(repo_name, base_dir)
        if df is not None:
            repositories_data[repo_name] = df
        else:
            print(f"WARNING: Could not load data for {repo_name}")
    
    if not repositories_data:
        print("ERROR: No repository data could be loaded. Check that the CSV files exist.")
        return
    
    # Create summary dashboard
    print("Creating summary dashboard...")
    create_summary_dashboard(repositories_data, output_dir)
    
    # Visualize RQ1: High severity vulnerabilities
    print("Visualizing RQ1: High severity vulnerabilities...")
    rq1_summary = visualize_rq1_high_severity(repositories_data, output_dir)
    
    # Visualize RQ2: Severity patterns
    print("Visualizing RQ2: Severity patterns...")
    rq2_summary = visualize_rq2_severity_patterns(repositories_data, output_dir)
    
    # Visualize RQ3: CWE analysis
    print("Visualizing RQ3: CWE analysis...")
    rq3_summary = visualize_rq3_cwe_analysis(repositories_data, output_dir)
    
    # Save consolidated report
    report = {
        "research_questions": {
            "rq1": rq1_summary,
            "rq2": rq2_summary,
            "rq3": rq3_summary
        }
    }
    
    with open(os.path.join(output_dir, "visualization_report.json"), "w") as f:
        json.dump(report, f, indent=2)
    
    print("Analysis visualizations complete! Results saved to:", output_dir)

if __name__ == "__main__":
    main()
